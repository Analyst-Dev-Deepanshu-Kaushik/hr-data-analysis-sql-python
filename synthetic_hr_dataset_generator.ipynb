{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17604a55-555f-4c5e-a64a-c0fd35c80555",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; color: black;\">\n",
    "    <h1>üìä Synthetic HR Analytics Dataset Generator</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5d8e85-3a32-4781-8d24-91b1db183fe2",
   "metadata": {},
   "source": [
    "#### **This notebook creates a realistic employee lifecycle dataset for HR analytics and dashboard development. It simulates departments, job roles, employee demographics, salary progression, performance reviews, promotions, attrition events, and hiring sources ‚Äî all generated using Python and the Faker library. Ideal for powering tools like Streamlit, Power BI, and Tableau.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615da566-3c0b-428f-ac6f-228484301761",
   "metadata": {},
   "source": [
    "### üîß Step 1: Import Required Libraries\n",
    "We begin by loading essential Python libraries used for data manipulation (`pandas`, `numpy`), synthetic data generation (`Faker`, `random`), date computations, and file management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "204b8986-91fc-48f7-94f0-f3ffdbfb8e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas and numpy for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# faker for generating realistic synthetic values (names, dates, etc.)\n",
    "from faker import Faker\n",
    "# random and datetime for reproducibility and date operations\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f663b01-1aa2-4802-84e9-27eae1d04edf",
   "metadata": {},
   "source": [
    "### üé≤ Step 2: Initialize Faker and Seed Generators\n",
    "Faker will be used to create realistic names and dates. Random seeds ensure reproducibility ‚Äî the same synthetic dataset will be generated each time the notebook runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43375f08-64dc-49c4-b7e0-9680685928a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensures reproducibility of synthetic data across runs\n",
    "fake = Faker()\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ecdf88-9d07-42a8-9321-76d25bed753a",
   "metadata": {},
   "source": [
    "### üóÇÔ∏è Step 3: Set Up Output Directory\n",
    "All generated datasets will be stored in a dedicated folder named `hr_synthetic_data`. This keeps the workspace clean and organized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be255895-cc7b-4729-91ff-049c43c031be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folder to store generated HR datasets\n",
    "output_dir = \"hr_synthetic_data\"\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40e6ede-d69f-47c5-aabd-3232673e865f",
   "metadata": {},
   "source": [
    "### üè¢ Step 4: Create Department Reference Table\n",
    "We define a fixed list of departments and assign unique IDs to each. This acts as a reference for linking job roles and employees to departments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7b45c71-494d-4884-9257-9575f2b81e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define list of departments used across the organization\n",
    "departments = [\"Human Resources\", \"Engineering\", \"Sales\", \"Marketing\", \"Finance\", \"Legal\", \"IT Support\", \"Operations\"]\n",
    "# Assign unique IDs to each department and build DataFrame\n",
    "department_df = pd.DataFrame({\n",
    "    \"department_id\": range(1, len(departments) + 1),\n",
    "    \"department_name\": departments\n",
    "})\n",
    "# üíæ Save department table as CSV for reference during employee data generation\n",
    "department_df.to_csv(f\"{output_dir}/departments.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1115c27-0c50-45f0-9e54-1c404b5f3eec",
   "metadata": {},
   "source": [
    "### üëî Step 5: Create Job Roles Table\n",
    "This step defines a detailed list of job roles across all departments. Each role is mapped to its corresponding department using a `department_id`. This lookup table will serve as the backbone for assigning job roles to synthetic employees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73e1a942-9625-43c0-9aab-0eac3f8732b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each tuple contains (Job Role Name, Associated Department ID)\n",
    "job_roles = [\n",
    "    # HR Department (ID: 1)\n",
    "    (\"HR Manager\", 1), (\"HR Coordinator\", 1), (\"Talent Acquisition Specialist\", 1), \n",
    "    (\"Learning & Development Manager\", 1), (\"HR Analyst\", 1),\n",
    "    # Engineering Department (ID: 2)\n",
    "    (\"Software Engineer/Developer\", 2), (\"Web Developer\", 2), (\"Data Scientist\", 2),\n",
    "    (\"DevOps Engineer\", 2), (\"Data Engineer\", 2), (\"QA/Test Engineer\", 2), (\"Machine Learning Engineer\", 2),\n",
    "    # Sales Department (ID: 3)\n",
    "    (\"Sales Executive/Representative\", 3), (\"Account Manager\", 3), (\"Business Development Manager\", 3),\n",
    "    (\"Sales Operations Analyst\", 3), (\"Regional Sales Manager\", 3), (\"Inside Sales Coordinator\", 3),\n",
    "    # Marketing Department (ID: 4)\n",
    "    (\"Marketing Manager\", 4), (\"Content Strategist/Copywriter\", 4), (\"Digital Marketing Specialist\", 4),\n",
    "    (\"SEO/SEM Analyst\", 4), (\"Social Media Manager\", 4), (\"Brand Manager\", 4), (\"Marketing Analyst\", 4),\n",
    "    # Finance Department (ID: 5)\n",
    "    (\"Accountant\", 5), (\"Financial Analyst\", 5), (\"Controller\", 5), (\"Auditor\", 5),\n",
    "    (\"Budget Analyst\", 5), (\"Payroll Manager\", 5), (\"Tax Specialist\", 5),\n",
    "    # Legal Department (ID: 6)\n",
    "    (\"Legal Counsel / Corporate Lawyer\", 6), (\"Paralegal\", 6), (\"Compliance Officer\", 6),\n",
    "    (\"Contract Manager\", 6), (\"Intellectual Property Specialist\", 6), \n",
    "    (\"Legal Operations Manager\", 6), (\"Risk Analyst\", 6),\n",
    "    # IT Support Department (ID: 7)\n",
    "    (\"IT Support Specialist / Technician\", 7), (\"Help Desk Analyst\", 7), \n",
    "    (\"System Administrator\", 7), (\"Network Administrator\", 7),\n",
    "    (\"IT Security Analyst\", 7), (\"Desktop Support Engineer\", 7),\n",
    "    # Operations Department (ID: 8)\n",
    "    (\"Operations Manager\", 8), (\"Operations/Logistics Coordinator\", 8), \n",
    "    (\"Supply Chain Analyst\", 8), (\"Warehouse Manager\", 8),\n",
    "    (\"Business Operations Analyst\", 8), (\"Inventory Manager\", 8)\n",
    "]\n",
    "# üîÑ Convert job role list to a DataFrame with role IDs and associated departments\n",
    "job_role_df = pd.DataFrame({\n",
    "    \"job_role_id\": range(1, len(job_roles) + 1),\n",
    "    \"job_role_name\": [jr[0] for jr in job_roles],\n",
    "    \"department_id\": [jr[1] for jr in job_roles]\n",
    "})\n",
    "# üíæ Save job roles with department linkage\n",
    "job_role_df.to_csv(f\"{output_dir}/job_roles.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727b94db-9b2b-419b-8086-f7c077785c83",
   "metadata": {},
   "source": [
    "### üë• Step 6: Generate Synthetic Employee Profiles\n",
    "Using the `Faker` library and controlled randomization, we simulate 5000 employees. Each record includes:\n",
    "- Name, age, gender, marital status, and ethnicity\n",
    "- Country and department affiliation\n",
    "- Assigned job role and salary\n",
    "- Hire date and age distribution\n",
    "\n",
    "We clip extreme salary values to ensure realism and save the result as `employees.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1121e346-4e77-40f2-aa33-c02c15347c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of employee records to generate\n",
    "num_of_employees = 5000\n",
    "# Define sample values for categorical diversity\n",
    "ethnicity_choices = [\"White\", \"Black\", \"Asian\", \"Hispanic\", \"Native American\", \"Mixed\", \"Other\"]\n",
    "country_choices = [\"United States\", \"United Kingdom\", \"India\", \"Canada\", \"Germany\", \"Australia\", \"Nigeria\", \"Brazil\", \"Japan\", \"Spain\", \"France\", \"Italy\", \"South Korea\", \"New Zealand\", \"Singapore\"]\n",
    "marital_status_choices = [\"Single\", \"Married\", \"Divorced\", \"Separated\", \"Widowed\", \"Other\", \"Prefer not to say\"]\n",
    "employees = []\n",
    "for i in range(1, num_of_employees + 1):    \n",
    "    # üé≤ Randomize basic demographics\n",
    "    gender = random.choice([\"Male\", \"Female\"])\n",
    "    first_name = fake.first_name_male() if gender == \"Male\" else fake.first_name_female()\n",
    "    last_name = fake.last_name()\n",
    "    full_name = f\"{first_name} {last_name}\"    \n",
    "    # üëî Randomly assign job role (linked to department)\n",
    "    job_role = random.choice(job_role_df.to_dict(\"records\"))    \n",
    "    # üìÜ Generate realistic hire date and age\n",
    "    age = random.randint(21, 60)\n",
    "    hire_date = fake.date_between(start_date=\"-10y\", end_date=\"-30d\")   \n",
    "    # üßæ Build employee record dictionary\n",
    "    employee = {\n",
    "        \"employee_id\": i,\n",
    "        \"name\": full_name,\n",
    "        \"age\": age,\n",
    "        \"gender\": gender,\n",
    "        \"marital_status\": random.choice(marital_status_choices),\n",
    "        \"ethnicity\": random.choice(ethnicity_choices),\n",
    "        \"country\": random.choice(country_choices),\n",
    "        \"job_role_id\": job_role[\"job_role_id\"],\n",
    "        \"department_id\": job_role[\"department_id\"],\n",
    "        \"hire_date\": hire_date,\n",
    "        \"salary\": round(np.random.normal(loc=70000, scale=20000), 2)\n",
    "    }  \n",
    "    employees.append(employee)\n",
    "# üìä Convert to DataFrame and clip unrealistic salaries\n",
    "employee_df = pd.DataFrame(employees)\n",
    "employee_df[\"salary\"] = employee_df[\"salary\"].clip(lower=30000, upper=150000)\n",
    "# üíæ Save employee dataset as CSV\n",
    "employee_df.to_csv(f\"{output_dir}/employees.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce442bf-6651-4622-8f0e-de8464c25eea",
   "metadata": {},
   "source": [
    "### üí∞ Step 7: Create Salary Progression Records\n",
    "To reflect career growth, we simulate annual salary adjustments for each employee. Salary increases are modeled as a 3% linear raise per year. Each entry includes the employee ID, effective date, and adjusted salary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19eac820-e4f6-415c-bcbf-6eca6844a190",
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_history = []\n",
    "for _, row in employee_df.iterrows():\n",
    "    # Random number of salary records per employee (simulate raises)\n",
    "    num_records = random.randint(1, 3)\n",
    "    base_salary = row[\"salary\"]\n",
    "    hire_date = pd.to_datetime(row[\"hire_date\"])\n",
    "    for i in range(num_records):\n",
    "        # Create an effective date spaced by 1-year intervals\n",
    "        effective_date = (hire_date + timedelta(days=365 * i)).strftime(\"%Y-%m-%d\")\n",
    "        # Assume a 3% raise per year (simple linear growth)\n",
    "        salary = round(base_salary * (1 + 0.03 * i), 2)\n",
    "        salary_history.append({\n",
    "            \"employee_id\": row[\"employee_id\"],\n",
    "            \"effective_date\": effective_date,\n",
    "            \"salary_amount\": salary\n",
    "        })\n",
    "# üìÑ Convert salary records to DataFrame and save\n",
    "salary_df = pd.DataFrame(salary_history)\n",
    "salary_df.to_csv(f\"{output_dir}/salaries.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7dda2a-9844-417a-a272-68734932ca85",
   "metadata": {},
   "source": [
    "### üìà Step 8: Create Employee Performance Reviews\n",
    "We simulate periodic performance reviews for each employee, spaced yearly after their hire date. Each review includes:\n",
    "- Review date\n",
    "- A score from 1 to 5\n",
    "- Eligibility for bonuses\n",
    "\n",
    "Reviews scheduled beyond today‚Äôs date are excluded to maintain realism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f26e0ded-01a3-46ca-b2ff-9638ad3c1c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_reviews = []\n",
    "for _, row in employee_df.iterrows():\n",
    "    num_reviews = random.randint(1, 4)\n",
    "    hire_date = pd.to_datetime(row['hire_date'])\n",
    "    for i in range(num_reviews):\n",
    "        # Reviews occur annually post-hire\n",
    "        review_date = hire_date + timedelta(days=365 * (i + 1))\n",
    "        # Skip reviews set in the future\n",
    "        if review_date > datetime.now():\n",
    "            break\n",
    "        performance_reviews.append({\n",
    "            \"employee_id\": row['employee_id'],\n",
    "            \"review_date\": review_date.strftime('%Y-%m-%d'),\n",
    "            \"performance_score\": random.randint(1, 5),\n",
    "            \"bonus_eligible\": random.choice([True, False])\n",
    "        })\n",
    "# üìÑ Save performance review history\n",
    "performance_reviews_df = pd.DataFrame(performance_reviews)\n",
    "performance_reviews_df.to_csv(f\"{output_dir}/performance_reviews.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f41de14-c891-4806-bb66-14777c8d9dee",
   "metadata": {},
   "source": [
    "### üö™ Step 9: Generate Employee Attrition Events\n",
    "About 25% of employees are flagged as separated. Each attrition record includes:\n",
    "- Exit date\n",
    "- Reason (Resigned, Fired, Retired, Layoff, etc.)\n",
    "- Whether the exit was voluntary\n",
    "- Satisfaction rating at time of departure\n",
    "\n",
    "Exit dates are constrained to occur post-hire and prior to today."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "790e6357-e0d3-4e20-a297-e5bb6bc234a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "attrition_records = []\n",
    "for _, row in employee_df.iterrows():\n",
    "    # Approx 25% employees experience attrition\n",
    "    if random.random() < 0.25:\n",
    "        hire_date = pd.to_datetime(row['hire_date'])\n",
    "        exit_date = hire_date + timedelta(days=random.randint(365, 365 * 8))\n",
    "        # Skip future exits\n",
    "        if exit_date > datetime.now():\n",
    "            continue\n",
    "        # Determine reason based on age profile\n",
    "        age = row['age']  # üîß Added: pull age from row to fix logical scope\n",
    "        if age >= 55:\n",
    "            reason = random.choice([\"Resigned\", \"Retired\", \"Layoff\"])\n",
    "        else:\n",
    "            reason = random.choice([\"Resigned\", \"Fired\", \"Layoff\"])\n",
    "        attrition_records.append({\n",
    "            \"employee_id\": row['employee_id'],\n",
    "            \"exit_date\": exit_date.strftime('%Y-%m-%d'),\n",
    "            \"reason\": reason,\n",
    "            \"voluntary_exit\": reason in [\"Resigned\", \"Retired\"],\n",
    "            \"satisfaction_rating\": random.randint(1, 5)\n",
    "        })\n",
    "# üìÑ Save synthetic attrition data\n",
    "attrition_df = pd.DataFrame(attrition_records)\n",
    "attrition_df.to_csv(f\"{output_dir}/attrition.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b70dc65-c5cf-4399-b48b-749ee202d59b",
   "metadata": {},
   "source": [
    "### üéì Step 10: Record Employee Promotions\n",
    "A subset of employees (approx. 15%) are assigned a promotion during their tenure. This includes:\n",
    "- Promotion date\n",
    "- New job role assignment\n",
    "\n",
    "Promotions are constrained to occur within a realistic time window and not in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "273369d0-5705-4e90-b05b-78491f868706",
   "metadata": {},
   "outputs": [],
   "source": [
    "promotion_records = []\n",
    "for _, row in employee_df.iterrows():\n",
    "    # Approx. 15% of employees get promoted\n",
    "    if random.random() < 0.15:\n",
    "        # Promotion occurs 1‚Äì5.5 years after hire\n",
    "        promotion_date = pd.to_datetime(row['hire_date']) + timedelta(days=random.randint(365, 2000))\n",
    "        # Exclude promotions that occur in the future\n",
    "        if promotion_date > datetime.now():\n",
    "            continue\n",
    "        # Randomly assign a new job role ID to simulate upward movement\n",
    "        new_role = random.choice(job_role_df['job_role_id'].tolist())\n",
    "        promotion_records.append({\n",
    "            'employee_id': row['employee_id'],\n",
    "            'promotion_date': promotion_date.strftime('%Y-%m-%d'),\n",
    "            'new_job_role_id': new_role\n",
    "        })\n",
    "# üìÑ Convert to DataFrame and save promotion history\n",
    "promotion_df = pd.DataFrame(promotion_records)\n",
    "promotion_df.to_csv(f\"{output_dir}/promotions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8225d70e-4cdc-401c-beaf-f577c36e8b73",
   "metadata": {},
   "source": [
    "### üîç Step 11: Assign Hiring Sources\n",
    "Each employee is associated with a hiring source (e.g. Referral, Job Board, Career Fair). If sourced via referral, a referring person is also noted using Faker. <br>\n",
    "This information supports analysis of recruitment effectiveness and referral trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4430653d-f577-4193-a3d8-dad7dde863bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = ['Referral', 'Job Board', 'Career Fair', 'Recruitment Agency', 'Internal Transfer', 'Social Media']\n",
    "hiring_sources = []\n",
    "for _, row in employee_df.iterrows():\n",
    "    # Randomly assign one source per employee\n",
    "    source = random.choice(sources)\n",
    "    hiring_sources.append({\n",
    "        'employee_id': row['employee_id'],\n",
    "        'hiring_source': source,\n",
    "        # Only populate 'referred_by' if source is 'Referral'\n",
    "        'referred_by': fake.name() if source == 'Referral' else None\n",
    "    })\n",
    "# üìÑ Save hiring source details for analytical insights\n",
    "hiring_sources_df = pd.DataFrame(hiring_sources)\n",
    "hiring_sources_df.to_csv(f\"{output_dir}/hiring_sources.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065dcfff-254a-4618-a31e-d78bc94c879c",
   "metadata": {},
   "source": [
    "### ‚úÖ Final Summary\n",
    "\n",
    "In this notebook, we've programmatically generated a full-spectrum synthetic HR dataset simulating realistic employee lifecycle events. Through modular steps, we created:\n",
    "\n",
    "- üè¢ Department and Job Role mappings\n",
    "- üë• Employee profiles with demographics and employment metadata\n",
    "- üí∞ Salary history with annual progression\n",
    "- üìà Performance review cycles with ratings and bonus eligibility\n",
    "- üö™ Attrition patterns including exit reasons and satisfaction scores\n",
    "- üéì Promotion records reflecting internal mobility\n",
    "- üîç Hiring source insights for recruitment analysis\n",
    "\n",
    "This dataset supports use cases such as:\n",
    "- HR analytics dashboards (Streamlit, Power BI, Tableau)\n",
    "- Machine learning on attrition prediction or performance modeling\n",
    "- Data visualization and KPI storytelling\n",
    "- Prototyping enterprise-grade applications with realistic personnel data\n",
    "\n",
    "Built with reusability and extensibility in mind, this pipeline can scale across industries or serve as the foundation for advanced analytics projects.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcfc15c-8a6d-4409-9ad7-058bd88bf5dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
